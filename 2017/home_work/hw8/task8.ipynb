{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">Домашнее задание №8 </span>\n",
    "\n",
    "<span style=\"color: red; font-size: 14pt\">Deadline: 20.05.2017 23:59:59</span>\n",
    "\n",
    "<span style=\"font-size: 10pt\">ФИВТ, АПТ, Курс по машинному обучению, Весна 2017, Модуль Unspervised Learning, </span>\n",
    "\n",
    "<span style=\"color:blue; font-size: 10pt\">Alexey Romanenko, </span>\n",
    "<span style=\"color:blue; font-size: 10pt; font-family: 'Verdana'\">alexromsput@gmail.com</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Воронцов К. В. Математические методы обучения по прецедентам. 2012. http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf (разделы 5.2 и 7.1)\n",
    "- Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning. Springer: Data Mining, Inference, and Prediction.  — 2nd ed. — Springer-Verlag. 2009. — 746 p.http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf (глава 14)\n",
    "\n",
    "\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2017_fall <номер_группы> <фамилия>``, к примеру -- ``ML2017_fall 496 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2017_496_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Дедлайн жесткий, в том числе помтоу что это ДЗ последнее в курсе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Контрольные вопросы (0 % - для самоконтроля) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: В чём заключается проблема мультиколлинеарности?\n",
    "\n",
    "**Вопрос 2**: Какие проблемы при обучении алгоритмов возникают из-за большой разамерности пространства признаков?\n",
    "\n",
    "**Вопрос 3**: В чем суть проклятия размерности?\n",
    "\n",
    "** Вопрос 4**: Какая связь между решением задачи PCA и SVD-разложение матрицы регрессии?\n",
    "\n",
    "** Вопрос 5**: Почему в tSNE расстояние между парамми объектов измеряется \"по-стьюденту\" и как это помогает решить проблему \"скрученности\" (crowding problem)?\n",
    "\n",
    "**Вопрос 6**: На какой идее базируются алгоритмы аггломеративной кластеризации? Напишите формулу Ланса-Вильма\n",
    "\n",
    "**Вопрос 7**: Какие два шага выделяют в алгоритме кластеризации k-means?\n",
    "\n",
    "**Вопрос 8**: В чём отличия (основные упрощения) k-means от EM-алгоритма кластеризации?\n",
    "\n",
    "** Вопрос 9 **Какой принцип работы графовых алгоритмов кластеризации?\n",
    "\n",
    "** Вопрос 10 **  В чем некорректность постановки задачи кластеризации?\n",
    "\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Вопросы по теории (30%) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 1 ** \n",
    "Ответьте на вопросы:\n",
    "\n",
    " 1) Как можно не прибегая к визуализации понять, что кластерная структура у данного облака точек отсутствует?\n",
    " 2) Какие из алгоритмов кластеризации могут выделять кластеры с ленточной структурой? \n",
    " 3) Какие алгоритмы кластеризации чувствительны к шуму и перемычкам?\n",
    " 4) Каким образом приближают «центр кластера» в нелинейных пространствах?\n",
    " 5) Каким образом можно определять число кластеров?\n",
    " \n",
    "** Задача 2 **\n",
    "Даны пять точек на числовой оси $X = (1; 5; 7; 8; 8)$, число кластеров равно 2. Рассчитайте ответ алгоритма  K-means (финальные центры кластеров), если начальные центры кластеров c1 = 1, c2 = 10.\n",
    "\n",
    "** Задача 3 **\n",
    "Докажите, что the k-means всегда сходится.\n",
    "\n",
    "** Задача 4 **\n",
    "Для сжатия размерности пространства алгоритм PCA применяется датасету с количеством признаков $D = 100$. Наблюдается следующий спектр собственных значений матрицы объектов-признаков. \n",
    "<img src=\"PCA_lambda.png\" width=\"600\">\n",
    "Ответье на вопросы\n",
    "\n",
    "* 1) Высокая ли эффективная размерность пространства признаков (intrinsic dimensionality) (насколько она близка к 100)?\n",
    "* 2) Можно ли перевести датасет с помощью PCA в пространство меньшей размерности с минимальными потерями точности? Если да, то чему примерно будет равна размернось "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Практическое задание 1 (30%) </h2>\n",
    "Реализуйте PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "'''\n",
    "Performs the Principal Coponent analysis of the Matrix F\n",
    "Matrix must be n * l dimensions\n",
    "where n is # features\n",
    "l is # samples\n",
    "'''\n",
    "\n",
    "def PCA(F, varRetained = 0.95, show = False):\n",
    "    # Input\n",
    "    #     F - initaial matrix \n",
    "    # Compute Covariance Matrix Sigma\n",
    "    # Input\n",
    "    (n, l) = F.shape\n",
    "    Sigma = 1.0 / l * F * np.transpose(F)\n",
    "    # Compute eigenvectors and eigenvalues of Sigma by SVD\n",
    "    # U, V - matrix, d - array: Sigma = U * np.diag(d) * V\n",
    "    U, d, V = посчитать SVD матрицы Sigma\n",
    "\n",
    "    # compute the value m: number of minumum features that retains the given variance varRetaine\n",
    "    dTot = np.sum(d)\n",
    "    var_i = np.array([np.sum(d[: i + 1]) / \\\n",
    "                dTot * 100.0 for i in range(n)])\n",
    "    m = вычислите необходимое число главных компонент\n",
    "    print '%.2f %% variance retained in %m dimensions' % верните число m и точность, которая достигается при этом числе главных компонент\n",
    "\n",
    "    # plot the variance plot\n",
    "    if show:\n",
    "        plt.plot(var_i)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel(' Percentage Variance retained')\n",
    "        plt.title('PCA $\\% \\sigma^2 $ vs # features')\n",
    "        plt.show()\n",
    "\n",
    "    # compute the reduced dimensional features by projection\n",
    "    U_reduced = только m главных компонент\n",
    "    G = вычислить матрицу в преобразованном пространстве\n",
    "\n",
    "    return G, U_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Примените алгоритм к данным MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# PCA of training set\n",
    "print 'Performing PCA - Principal COmponent Analysis'\n",
    "\n",
    "Z, U_reduced = PCA(X.T, varRetained = 0.95, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print Z\n",
    "print U_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><h2 align=\"center\">Практическое задание 2 (40%) </h2> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"left\">Изучение алгоритмов кластеризации на разных выборках</h2>\n",
    "\n",
    "### Кластеризация цифр с помощью dbscan\n",
    "На данных из sklearn.datasets.load_digits примените алгоритмы кластеризации (знания о метках классов при кластеризации использовать нельзя):\n",
    " - <a href='http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN'>dbscan </a> \n",
    " запускайте при различных параметрах eps и minsamples, для всех экспериментов можете выбрать одну метрику (вспомните семинар про  метрические алгоритмы);\n",
    " - Используя метки классов цифр, оцените качество различных кластеризаций при помощи Adjusted Mutual Information и Adjusted Rand Index. \n",
    " - визуалируйте изображения тех цифр, которые соответствуют core_points;\n",
    " - визуалируйте изображения тех цифр, которые соответствуют выбросам;\n",
    " - сделайте выводы и применимости алгоритмов.\n",
    "\n",
    "### Уменьшение палитры изображения\n",
    " - для <a href=\"https://thumbs.dreamstime.com/x/two-lorikeet-birds-2293918.jpg\"> картинки </a> \n",
    "нужно уменьшить число цветов в палитре; для этого нужно выделить кластеры в пространстве RGB, объекты соответствуют пикселам изображения; после выделения кластеров,\n",
    "все пикселы, отнесенные в один кластер, заполняются одним цветом; этот цвет может быть центроидом соответствующего кластера, медианным цветом по кластеру. \n",
    " - Попробуйте различные алгоритмы кластеризации:\n",
    "        -- KMeans\n",
    "        -- MeanShift\n",
    "        -- AgglomerativeClustering\n",
    "   Рассмотрите число кластеров K = 2, 3, 10, 20\n",
    " - Для различных кластеризаций оцените и сравните потери от уменьшения цветов при помощи\n",
    "метрики <a href=\"http://scikit-image.org/docs/dev/api/skimage.measure.html\"> SSIM</a>. Какой способ оказался лучшим?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
